{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to study real dual conversations and model what people are talking about in various contexts and their emotions in expressing themselves.\n",
    "Each multi-turn conversations \\([dialogues_text.txt](dialogues_text.txt)\\) has been annotated with: \n",
    "* one dialogue act for each turn \\([dialogues_act.txt](dialogues_act.txt)\\)\n",
    "* one emotion of the speaker for each turn \\([dialogues_emotion.txt](dialogues_emotion.txt)\\) \n",
    "* an overall conversation topic \\([dialogues_topic.txt](dialogues_topic.txt)\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1. Use proper data science techniques to ingest the raw data into a form amenable for analysis.\n",
    "Importing some useful libraries and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "\n",
    "DB_FILE = 'task-1.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to read tab/space separated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNumeric(file):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            # Splitting separated values\n",
    "            result = re.compile(\"\\s\").split(line.strip())\n",
    "            # Casting values as integers\n",
    "            result = [int(x) for x in result]\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping numeric values into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listAct = [x for x in readNumeric(\"dialogues_act.txt\")]\n",
    "listEmotion = [x for x in readNumeric(\"dialogues_emotion.txt\")]\n",
    "listTopic = [x for x in readNumeric(\"dialogues_topic.txt\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(listAct[0:2])\n",
    "print(listEmotion[0:2])\n",
    "print(listTopic[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As word-tokenization might not be useful at this point, defining a function to *detokenize* (and fix inconsistencies on apostrophes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(str):\n",
    "    # punctuation join\n",
    "    str = re.sub(r\" +([!\\?\\.,;:])\", r\"\\1\", str)\n",
    "    # plural apostrophe join\n",
    "    str = re.sub(r\"s +['’]\", \"s'\", str)\n",
    "    # other apostrophes join\n",
    "    str = re.sub(r\" +['’] *\", \"'\", str)\n",
    "    # parenthetical info removal\n",
    "    str = re.sub(r\" *\\([^\\)]*\\)\", \"\", str)\n",
    "    # trimming\n",
    "    return str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to read the conversations' files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readConversation(file):\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # Splitting utterances -last(empty)\n",
    "            result = line.split(\"__eou__\")[:-1]\n",
    "            # Detokenizing for now\n",
    "            yield [detokenize(x) for x in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping conversations into a list and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listText = [x for x in readConversation(\"dialogues_text.txt\")]\n",
    "listText[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating relational database using SQLite and [this schema](ddl.sql.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_FILE)\n",
    "with open(\"ddl.sql.txt\") as f:\n",
    "    for line in f:\n",
    "        conn.execute(line)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to unfold lists into tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnfoldedList(myList):\n",
    "    for cId, container in enumerate(myList, start=1):\n",
    "        for uId, value in enumerate(container, start=1):\n",
    "            yield (cId, uId, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t for t in getUnfoldedList(listText[0:2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to generically write into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertInto(myTable, myList):\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.executemany(\"INSERT INTO \" + myTable + \" VALUES (?, ?, ?)\", getUnfoldedList(myList))\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingesting the data on the database, for the posterior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertInto(\"utterance\", listText)\n",
    "insertInto(\"utterance_act\", listAct)\n",
    "insertInto(\"utterance_emotion\", listEmotion)\n",
    "insertInto(\"conversation_topic\", listTopic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the database with a random conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT topicId, actId, emotionId, Utterance FROM utterance AS u\n",
    " INNER JOIN conversation_topic AS t ON (t.cId = u.cId)\n",
    " INNER JOIN utterance_act AS a ON (a.cId = u.cId AND a.uId = u.uId)\n",
    " INNER JOIN utterance_emotion AS e ON (e.cId = u.cId AND e.uId = u.uId)\n",
    "WHERE u.cId IN (\n",
    " SELECT cId FROM conversation_topic ORDER BY RANDOM() LIMIT 1\n",
    ") \n",
    "'''\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "for row in conn.execute(sql):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2. Analysis of the data** continues [here](2-analysis.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

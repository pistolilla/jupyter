{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to study real dual conversations and model what people are talking about in various contexts and their emotions in expressing themselves.\n",
    "Each multi-turn conversations \\([dialogues_text.txt](dialogues_text.txt)\\) has been annotated with: \n",
    "* one dialogue act for each turn \\([dialogues_act.txt](dialogues_act.txt)\\)\n",
    "* one emotion of the speaker for each turn \\([dialogues_emotion.txt](dialogues_emotion.txt)\\) \n",
    "* an overall conversation topic \\([dialogues_topic.txt](dialogues_topic.txt)\\)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1. Use proper data science techniques to ingest the raw data into a form amenable for analysis.\n",
    "Importing libraries and defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "\n",
    "DB_FILE = 'task-1.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to read tab/space separated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readNumeric(file):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            # Splitting separated values\n",
    "            result = re.compile(\"\\s\").split(line.strip())\n",
    "            # Casting values as integers\n",
    "            result = [int(x) for x in result]\n",
    "            yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping numeric values into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listAct = [x for x in readNumeric(\"dialogues_act.txt\")]\n",
    "listEmotion = [x for x in readNumeric(\"dialogues_emotion.txt\")]\n",
    "listTopic = [x for x in readNumeric(\"dialogues_topic.txt\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4], [3, 4, 3, 1, 1]]\n",
      "[[2, 0], [4, 2, 0, 1, 0]]\n",
      "[[1], [1]]\n"
     ]
    }
   ],
   "source": [
    "print(listAct[0:2])\n",
    "print(listEmotion[0:2])\n",
    "print(listTopic[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As word-tokenization might not be useful at this point, defining a function to *detokenize* (and fix inconsistencies on apostrophes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(str):\n",
    "    # punctuation join\n",
    "    str = re.sub(r\" +([!\\?\\.,;:])\", r\"\\1\", str)\n",
    "    # plural apostrophe join\n",
    "    str = re.sub(r\"s +['’]\", \"s'\", str)\n",
    "    # other apostrophes join\n",
    "    str = re.sub(r\" +['’] *\", \"'\", str)\n",
    "    # parenthetical info removal\n",
    "    str = re.sub(r\" *\\([^\\)]*\\)\", \"\", str)\n",
    "    # trimming\n",
    "    return str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to read the conversations' files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readConversation(file):\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            # Splitting utterances -last(empty)\n",
    "            result = line.split(\"__eou__\")[:-1]\n",
    "            # Detokenizing for now\n",
    "            yield [detokenize(x) for x in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dumping conversations into a list and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The kitchen stinks.', \"I'll throw out the garbage.\"],\n",
       " ['So Dick, how about getting some coffee for tonight?',\n",
       "  \"Coffee? I don't honestly like that kind of stuff.\",\n",
       "  'Come on, you can at least try a little, besides your cigarette.',\n",
       "  \"What's wrong with that? Cigarette is the thing I go crazy for.\",\n",
       "  'Not for me, Dick.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listText = [x for x in readConversation(\"dialogues_text.txt\")]\n",
    "listText[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating relational database using SQLite and [this schema](ddl.sql.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_FILE)\n",
    "with open(\"ddl.sql.txt\") as f:\n",
    "    for line in f:\n",
    "        conn.execute(line)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to unfold lists into tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnfoldedList(myList):\n",
    "    for cId, container in enumerate(myList, start=1):\n",
    "        for uId, value in enumerate(container, start=1):\n",
    "            yield (cId, uId, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 'The kitchen stinks.'),\n",
       " (1, 2, \"I'll throw out the garbage.\"),\n",
       " (2, 1, 'So Dick, how about getting some coffee for tonight?'),\n",
       " (2, 2, \"Coffee? I don't honestly like that kind of stuff.\"),\n",
       " (2, 3, 'Come on, you can at least try a little, besides your cigarette.'),\n",
       " (2, 4, \"What's wrong with that? Cigarette is the thing I go crazy for.\"),\n",
       " (2, 5, 'Not for me, Dick.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t for t in getUnfoldedList(listText[0:2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to generically write into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertInto(myTable, myList):\n",
    "    conn = sqlite3.connect(DB_FILE)\n",
    "    c = conn.cursor()\n",
    "    c.executemany(\"INSERT INTO \" + myTable + \" VALUES (?, ?, ?)\", getUnfoldedList(myList))\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingesting the data on the database, for the posterior analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertInto(\"utterance\", listText)\n",
    "insertInto(\"utterance_act\", listAct)\n",
    "insertInto(\"utterance_emotion\", listEmotion)\n",
    "insertInto(\"conversation_topic\", listTopic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the database with a random conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 0, \"Why'd you pull me over?\")\n",
      "(1, 2, 0, 'Are you aware that you drove through a red light?')\n",
      "(1, 2, 6, 'I ran a red light?')\n",
      "(1, 1, 0, 'Yes, you did.')\n",
      "(1, 1, 0, \"I apologize, but I didn't realize that I did.\")\n",
      "(1, 2, 0, \"Weren't you taught that yellow means slow down, not speed up?\")\n",
      "(1, 1, 0, 'I did learn that.')\n",
      "(1, 2, 0, 'So, then why did you speed up?')\n",
      "(1, 1, 0, \"I don't know what to tell you.\")\n",
      "(1, 3, 0, \"I'm going to have to write you a ticket.\")\n",
      "(1, 4, 0, 'I understand.')\n",
      "(1, 3, 0, \"Here you go. Don't do that again.\")\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "SELECT topicId, actId, emotionId, Utterance FROM utterance AS u\n",
    " INNER JOIN conversation_topic AS t ON (t.cId = u.cId)\n",
    " INNER JOIN utterance_act AS a ON (a.cId = u.cId AND a.uId = u.uId)\n",
    " INNER JOIN utterance_emotion AS e ON (e.cId = u.cId AND e.uId = u.uId)\n",
    "WHERE u.cId IN (\n",
    " SELECT cId FROM conversation_topic ORDER BY RANDOM() LIMIT 1\n",
    ") \n",
    "'''\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "for row in conn.execute(sql):\n",
    "    print(row)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2. Dumping to spreadsheet** continues [here](2-dump.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

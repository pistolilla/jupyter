{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipe 3-4. Generating Co-occurrence Matrix\n",
    "Letâ€™s discuss one more method of feature engineering called a co-occurrence matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The co_occurrence_matrix function is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    vocab_to_index = { word:i for i, word in enumerate(vocab) }\n",
    "    # Create bigrams from all words in corpus\n",
    "    bi_grams = list(bigrams(corpus))\n",
    "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "    # Initialise co-occurrence matrix\n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
    "    # Loop through the bigrams taking the current and previous word: co_occurrence_matrix[current][previous]\n",
    "    # and the number of occurrences of the bigram.\n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "        pos_current = vocab_to_index[current]\n",
    "        pos_previous = vocab_to_index[previous]\n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
    "    # return the matrix and the index\n",
    "    return co_occurrence_matrix,vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the sentences for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['I', 'love', 'nlp'],\n",
    "            ['I', 'love','to' 'learn'],\n",
    "            ['nlp', 'is', 'future'],\n",
    "            ['nlp', 'is', 'cool']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create one list using many lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'love',\n",
       " 'nlp',\n",
       " 'I',\n",
       " 'love',\n",
       " 'tolearn',\n",
       " 'nlp',\n",
       " 'is',\n",
       " 'future',\n",
       " 'nlp',\n",
       " 'is',\n",
       " 'cool']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = list(itertools.chain.from_iterable(sentences))\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 1., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0.],\n",
       "        [2., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 2., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix, vocab_to_index = co_occurrence_matrix(merged)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nlp': 0, 'future': 1, 'I': 2, 'is': 3, 'cool': 4, 'love': 5, 'tolearn': 6}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         nlp  future    I   is  cool  love  tolearn\n",
      "nlp      0.0     1.0  0.0  0.0   0.0   1.0      1.0\n",
      "future   0.0     0.0  0.0  1.0   0.0   0.0      0.0\n",
      "I        1.0     0.0  0.0  0.0   0.0   0.0      0.0\n",
      "is       2.0     0.0  0.0  0.0   0.0   0.0      0.0\n",
      "cool     0.0     0.0  0.0  1.0   0.0   0.0      0.0\n",
      "love     0.0     0.0  2.0  0.0   0.0   0.0      0.0\n",
      "tolearn  0.0     0.0  0.0  0.0   0.0   1.0      0.0\n"
     ]
    }
   ],
   "source": [
    "CoMatrixFinal = pd.DataFrame(matrix, index=vocab_to_index, columns=vocab_to_index)\n",
    "print(CoMatrixFinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
